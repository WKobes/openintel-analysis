{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Do necessary imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "from pyspark.sql.functions import substring, expr\n",
    "import pandas as pd\n",
    "\n",
    "# Temporary imports to load avro files\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Start spark session\n",
    "sqlc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Master Thesis Analysis\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.2.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Constants\n",
    "FILE_PATH = \"openintel/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load AVRO files DNS RR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: connect to spark cluster, now manually load 1 avro folder for testing\n",
    "my_dnsrr_df = sqlc.read.format(\"avro\").load([join(FILE_PATH, f) for f in listdir(FILE_PATH) if isfile(join(FILE_PATH, f))])\n",
    "\n",
    "# Load the known domain names\n",
    "with open('CT-logs domeinen.txt', 'r') as f:\n",
    "    known_names = [line.strip() for line in f]\n",
    "\n",
    "with open('CT-logs domeinen.txt', 'r') as f:\n",
    "    known_names_with_dot = [line.strip() + '.' for line in f]    \n",
    "\n",
    "# TODO: delete this, manual overlap added for testing CT\n",
    "known_names.append(\"18dbf4a18e441d4e8d27b9dacdcb61348453.postgres.database.azure.com\")\n",
    "\n",
    "# Transform known domain names to dataframes\n",
    "my_known_names_df = sqlc.createDataFrame(pd.DataFrame({\"domain\": known_names }))\n",
    "my_known_names_with_dot_df = sqlc.createDataFrame(pd.DataFrame({\"query_name\": known_names_with_dot }))\n",
    "\n",
    "# Load the Resource Records into dataframes\n",
    "with open('CAA records.txt', 'r') as f:\n",
    "    caa_known = [line.split()[-1] for line in f]\n",
    "    caa_known_df = sqlc.createDataFrame(pd.DataFrame({\"caa_value\": caa_known }))\n",
    "\n",
    "with open('A IPv4 records.txt', 'r') as f:\n",
    "    ipv4_known = [line.strip() for line in f]\n",
    "    ipv4_known_df = sqlc.createDataFrame(pd.DataFrame({\"ip4_address\": ipv4_known }))\n",
    "    \n",
    "with open('MX records.txt', 'r') as f:\n",
    "    mx_known = [line.split()[-1] for line in f]\n",
    "    mx_known_df = sqlc.createDataFrame(pd.DataFrame({\"mx_address\": mx_known }))\n",
    "    \n",
    "with open('NS records.txt', 'r') as f:\n",
    "    ns_known = [line.strip() for line in f]    \n",
    "    ns_known_df = sqlc.createDataFrame(pd.DataFrame({\"ns_address\": ns_known }))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OpenINTEL analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select the data needed for every comparison\n",
    "caa_data = my_dnsrr_df.where(my_dnsrr_df.response_type == \"CAA\").select('query_name', 'caa_value')\n",
    "ipv4_data = my_dnsrr_df.where(my_dnsrr_df.response_type == \"A\").select('query_name', 'ip4_address')\n",
    "mx_data = my_dnsrr_df.where(my_dnsrr_df.response_type == \"MX\").select('query_name', 'mx_address')\n",
    "ns_data = my_dnsrr_df.where(my_dnsrr_df.response_type == \"NS\").select('query_name', 'ns_address')\n",
    "\n",
    "# Obtain results per type\n",
    "# First join on recognized value. Select only query name and only distinct values\n",
    "# Then anti join with known names to find new domains\n",
    "# Finally remove the trailing dot, since we need PQDNs for CT analysis\n",
    "# TODO: probably remove CAA\n",
    "caa_result = caa_data.join(caa_known_df, caa_data.caa_value == caa_known_df.caa_value, 'inner').select('query_name').distinct()\n",
    "caa_result = caa_result.join(my_known_names_with_dot_df, 'query_name', how='left_anti')\n",
    "caa_result = caa_result.withColumn(\"domain\", expr(\"substring(query_name, 1, length(query_name)-1)\")).select(\"domain\")\n",
    "caa_result.show(truncate=False)\n",
    "\n",
    "ipv4_result = ipv4_data.join(ipv4_known_df, ipv4_data.ip4_address == ipv4_known_df.ip4_address, 'inner').select('query_name').distinct()\n",
    "ipv4_result = ipv4_result.join(my_known_names_with_dot_df, 'query_name', how='left_anti')\n",
    "ipv4_result = ipv4_result.withColumn(\"domain\", expr(\"substring(query_name, 1, length(query_name)-1)\")).select(\"domain\")\n",
    "ipv4_result.show(truncate=False)\n",
    "\n",
    "mx_result = mx_data.join(mx_known_df, mx_data.mx_address == mx_known_df.mx_address, 'inner').select('query_name').distinct()\n",
    "mx_result = mx_result.join(my_known_names_with_dot_df, 'query_name', how='left_anti')\n",
    "mx_result = mx_result.withColumn(\"domain\", expr(\"substring(query_name, 1, length(query_name)-1)\")).select(\"domain\")\n",
    "mx_result.show(truncate=False)\n",
    "\n",
    "ns_result = ns_data.join(ns_known_df, ns_data.ns_address == ns_known_df.ns_address, 'inner').select('query_name').distinct()\n",
    "ns_result = ns_result.join(my_known_names_with_dot_df, 'query_name', how='left_anti')\n",
    "ns_result = ns_result.withColumn(\"domain\", expr(\"substring(query_name, 1, length(query_name)-1)\")).select(\"domain\")\n",
    "ns_result.show(truncate=False)\n",
    "\n",
    "# TODO: store intermediate results here for analysis\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join results with known domains.\n",
    "# Currently excluding CAA, because it appeared to be used by non-government domains as well.\n",
    "my_known_names_df = my_known_names_df.union(ipv4_result)\n",
    "my_known_names_df = my_known_names_df.union(mx_result)\n",
    "my_known_names_df = my_known_names_df.union(ns_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load AVRO files CT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: connect to spark cluster, now manually load 1 avro file for testing\n",
    "my_ct_df = sqlc.read.format(\"avro\").load(\"Google-Rocketeer.1117550000-1117574999.avro\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CT analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter the CT dataset on the known domain names\n",
    "result = my_ct_df.join(my_known_names_df, my_ct_df.leaf_cert.subject.CN == my_known_names_df.domain, \"inner\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the SAN off the certificates\n",
    "sans = result.select(result.leaf_cert.all_domains).collect()\n",
    "\n",
    "# Unique result set\n",
    "uni_results = set()\n",
    "\n",
    "# Loop rows\n",
    "for row in sans:\n",
    "    # Loop all_domain lists within row\n",
    "    for domain in row.__getitem__('leaf_cert.all_domains'):\n",
    "        # Add a domain to our set if it is not a wildcard domain + is not already in our known set.\n",
    "        # Since we use a set, we do not need to check for duplicates\n",
    "        if not domain.startswith('*') and domain not in known_names:\n",
    "            uni_results.add(domain)\n",
    "\n",
    "print(uni_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Store results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join results with known domains.\n",
    "# Currently excluding CAA, because it appeared to be used by non-government domains as well.\n",
    "my_known_names_df = my_known_names_df.union(ipv4_result)\n",
    "my_known_names_df = my_known_names_df.union(mx_result)\n",
    "my_known_names_df = my_known_names_df.union(ns_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load AVRO files CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: connect to spark cluster, now manually load 1 avro file for testing\n",
    "my_ct_df = sqlc.read.format(\"avro\").load(\"Google-Rocketeer.1117550000-1117574999.avro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CT analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the CT dataset on the known domain names\n",
    "result = my_ct_df.join(my_known_names_df, my_ct_df.leaf_cert.subject.CN == my_known_names_df.domain, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SAN off the certificates\n",
    "sans = result.select(result.leaf_cert.all_domains).collect()\n",
    "\n",
    "# Unique result set\n",
    "uni_results = set()\n",
    "\n",
    "# Loop rows\n",
    "for row in sans:\n",
    "    # Loop all_domain lists within row\n",
    "    for domain in row.__getitem__('leaf_cert.all_domains'):\n",
    "        # Add a domain to our set if it is not a wildcard domain + is not already in our known set.\n",
    "        # Since we use a set, we do not need to check for duplicates\n",
    "        if not domain.startswith('*') and domain not in known_names:\n",
    "            uni_results.add(domain)\n",
    "\n",
    "print(uni_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Store results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}